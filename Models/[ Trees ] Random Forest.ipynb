{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X,y = make_moons(n_samples = 500, noise = 0.3, random_state= 42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble     import RandomForestClassifier\n",
    "from sklearn.ensemble     import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm          import SVC\n",
    "\n",
    "log_clf = LogisticRegression(random_state = 42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(random_state = 42)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('lr', log_clf),('rf', rnd_clf),('svm', svm_clf)], voting = 'hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sltm-14\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\sltm-14\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sltm-14\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=42, solver='warn',\n",
       "                                                 tol=0.0001, verbose=0,\n",
       "                                                 warm_start=False)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     ma...\n",
       "                                                     n_jobs=None,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=42, verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             ('svm',\n",
       "                              SVC(C=1.0, cache_size=200, class_weight=None,\n",
       "                                  coef0=0.0, decision_function_shape='ovr',\n",
       "                                  degree=3, gamma='auto_deprecated',\n",
       "                                  kernel='rbf', max_iter=-1, probability=False,\n",
       "                                  random_state=42, shrinking=True, tol=0.001,\n",
       "                                  verbose=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.872\n",
      "SVC 0.888\n",
      "VotingClassifier 0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sltm-14\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\sltm-14\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sltm-14\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\sltm-14\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\sltm-14\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf,voting_clf):\n",
    "    clf.fit (X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__,accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOFT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble     import RandomForestClassifier\n",
    "from sklearn.ensemble     import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm          import SVC\n",
    "\n",
    "log_clf = LogisticRegression(random_state = 42)\n",
    "rnd_clf = RandomForestClassifier(random_state=42)\n",
    "svm_clf = SVC(probability=True,random_state = 42)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('lr', log_clf),('rf', rnd_clf),('svm', svm_clf)], voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sltm-14\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\sltm-14\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sltm-14\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=42, solver='warn',\n",
       "                                                 tol=0.0001, verbose=0,\n",
       "                                                 warm_start=False)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     ma...\n",
       "                                                     n_jobs=None,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=42, verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             ('svm',\n",
       "                              SVC(C=1.0, cache_size=200, class_weight=None,\n",
       "                                  coef0=0.0, decision_function_shape='ovr',\n",
       "                                  degree=3, gamma='auto_deprecated',\n",
       "                                  kernel='rbf', max_iter=-1, probability=True,\n",
       "                                  random_state=42, shrinking=True, tol=0.001,\n",
       "                                  verbose=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.872\n",
      "SVC 0.888\n",
      "VotingClassifier 0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sltm-14\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\sltm-14\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\sltm-14\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\sltm-14\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\sltm-14\\Anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf,voting_clf):\n",
    "    clf.fit (X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__,accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(random_state=42), \n",
    "                            n_estimators = 500, \n",
    "                            max_samples = 100, \n",
    "                            bootstrap = True, \n",
    "                            n_jobs = -1,\n",
    "                            random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf.fit(X_train,y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                        criterion='gini',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        presort=False,\n",
       "                                                        random_state=None,\n",
       "                                                        splitter='best'),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=1.0, n_estimators=500, n_jobs=-1, oob_score=True,\n",
       "                  random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf2=BaggingClassifier(DecisionTreeClassifier(), n_estimators=500,bootstrap=True,n_jobs=-1,oob_score=True)\n",
    "bag_clf2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8986666666666666"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf2.oob_score_ # Nos da la exactitud tomando en cuenta la base dde datos que se dió de entrenamiento no con los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32352941, 0.67647059],\n",
       "       [0.35625   , 0.64375   ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06145251, 0.93854749],\n",
       "       [0.35465116, 0.64534884],\n",
       "       [0.01142857, 0.98857143],\n",
       "       [0.98930481, 0.01069519],\n",
       "       [0.97409326, 0.02590674],\n",
       "       [0.7370892 , 0.2629108 ],\n",
       "       [0.0049505 , 0.9950495 ],\n",
       "       [0.75      , 0.25      ],\n",
       "       [0.82681564, 0.17318436],\n",
       "       [0.98461538, 0.01538462],\n",
       "       [0.06315789, 0.93684211],\n",
       "       [0.00490196, 0.99509804],\n",
       "       [0.99004975, 0.00995025],\n",
       "       [0.92513369, 0.07486631],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03409091, 0.96590909],\n",
       "       [0.34502924, 0.65497076],\n",
       "       [0.91666667, 0.08333333],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96319018, 0.03680982],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.65420561, 0.34579439],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0049505 , 0.9950495 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.19148936, 0.80851064],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00591716, 0.99408284],\n",
       "       [0.39751553, 0.60248447],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.23463687, 0.76536313],\n",
       "       [0.32777778, 0.67222222],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02906977, 0.97093023],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01183432, 0.98816568],\n",
       "       [0.97916667, 0.02083333],\n",
       "       [0.88297872, 0.11702128],\n",
       "       [0.94054054, 0.05945946],\n",
       "       [0.9558011 , 0.0441989 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06122449, 0.93877551],\n",
       "       [0.98026316, 0.01973684],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01005025, 0.98994975],\n",
       "       [0.98857143, 0.01142857],\n",
       "       [0.81868132, 0.18131868],\n",
       "       [0.45303867, 0.54696133],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.70860927, 0.29139073],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.84745763, 0.15254237],\n",
       "       [1.        , 0.        ],\n",
       "       [0.60526316, 0.39473684],\n",
       "       [0.12222222, 0.87777778],\n",
       "       [0.6284153 , 0.3715847 ],\n",
       "       [0.9017341 , 0.0982659 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.17204301, 0.82795699],\n",
       "       [0.90055249, 0.09944751],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00540541, 0.99459459],\n",
       "       [0.05780347, 0.94219653],\n",
       "       [0.02312139, 0.97687861],\n",
       "       [0.34337349, 0.65662651],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.82954545, 0.17045455],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.21276596, 0.78723404],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95811518, 0.04188482],\n",
       "       [0.81675393, 0.18324607],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.25274725, 0.74725275],\n",
       "       [0.56470588, 0.43529412],\n",
       "       [0.        , 1.        ],\n",
       "       [0.04255319, 0.95744681],\n",
       "       [0.50543478, 0.49456522],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01704545, 0.98295455],\n",
       "       [0.98913043, 0.01086957],\n",
       "       [0.20903955, 0.79096045],\n",
       "       [0.44692737, 0.55307263],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01570681, 0.98429319],\n",
       "       [0.98901099, 0.01098901],\n",
       "       [0.25698324, 0.74301676],\n",
       "       [0.87719298, 0.12280702],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.78285714, 0.21714286],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00578035, 0.99421965],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98895028, 0.01104972],\n",
       "       [0.99447514, 0.00552486],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96039604, 0.03960396],\n",
       "       [0.99497487, 0.00502513],\n",
       "       [0.01092896, 0.98907104],\n",
       "       [0.15662651, 0.84337349],\n",
       "       [0.95918367, 0.04081633],\n",
       "       [0.32727273, 0.67272727],\n",
       "       [0.98924731, 0.01075269],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.7251462 , 0.2748538 ],\n",
       "       [0.35632184, 0.64367816],\n",
       "       [0.4       , 0.6       ],\n",
       "       [0.85326087, 0.14673913],\n",
       "       [0.95918367, 0.04081633],\n",
       "       [0.06878307, 0.93121693],\n",
       "       [0.8030303 , 0.1969697 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03508772, 0.96491228],\n",
       "       [0.98342541, 0.01657459],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0052356 , 0.9947644 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01932367, 0.98067633],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95402299, 0.04597701],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.38674033, 0.61325967],\n",
       "       [0.27717391, 0.72282609],\n",
       "       [0.01117318, 0.98882682],\n",
       "       [0.        , 1.        ],\n",
       "       [0.30729167, 0.69270833],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99378882, 0.00621118],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98295455, 0.01704545],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00502513, 0.99497487],\n",
       "       [0.61271676, 0.38728324],\n",
       "       [0.91747573, 0.08252427],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99516908, 0.00483092],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.06930693, 0.93069307],\n",
       "       [1.        , 0.        ],\n",
       "       [0.05405405, 0.94594595],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.04294479, 0.95705521],\n",
       "       [1.        , 0.        ],\n",
       "       [0.93229167, 0.06770833],\n",
       "       [0.73295455, 0.26704545],\n",
       "       [0.61212121, 0.38787879],\n",
       "       [0.        , 1.        ],\n",
       "       [0.12244898, 0.87755102],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95731707, 0.04268293],\n",
       "       [0.96855346, 0.03144654],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02272727, 0.97727273],\n",
       "       [0.        , 1.        ],\n",
       "       [0.39664804, 0.60335196],\n",
       "       [0.85082873, 0.14917127],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99408284, 0.00591716],\n",
       "       [0.00520833, 0.99479167],\n",
       "       [0.00540541, 0.99459459],\n",
       "       [0.96111111, 0.03888889],\n",
       "       [0.        , 1.        ],\n",
       "       [0.30808081, 0.69191919],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00595238, 0.99404762],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96236559, 0.03763441],\n",
       "       [0.80246914, 0.19753086],\n",
       "       [0.995     , 0.005     ],\n",
       "       [0.00543478, 0.99456522],\n",
       "       [0.04411765, 0.95588235],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02808989, 0.97191011],\n",
       "       [0.        , 1.        ],\n",
       "       [0.05405405, 0.94594595],\n",
       "       [1.        , 0.        ],\n",
       "       [0.83888889, 0.16111111],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8988764 , 0.1011236 ],\n",
       "       [0.99450549, 0.00549451],\n",
       "       [0.18857143, 0.81142857],\n",
       "       [0.22651934, 0.77348066],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00549451, 0.99450549],\n",
       "       [0.        , 1.        ],\n",
       "       [0.23684211, 0.76315789],\n",
       "       [0.95744681, 0.04255319],\n",
       "       [0.00507614, 0.99492386],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.43956044, 0.56043956],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.04712042, 0.95287958],\n",
       "       [0.0982659 , 0.9017341 ],\n",
       "       [0.97959184, 0.02040816],\n",
       "       [0.02185792, 0.97814208],\n",
       "       [1.        , 0.        ],\n",
       "       [0.35106383, 0.64893617],\n",
       "       [0.13793103, 0.86206897],\n",
       "       [0.54891304, 0.45108696],\n",
       "       [0.65656566, 0.34343434],\n",
       "       [0.00558659, 0.99441341],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.64622642, 0.35377358],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.22164948, 0.77835052],\n",
       "       [0.81094527, 0.18905473],\n",
       "       [0.03012048, 0.96987952],\n",
       "       [1.        , 0.        ],\n",
       "       [0.86387435, 0.13612565],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00518135, 0.99481865],\n",
       "       [0.09137056, 0.90862944],\n",
       "       [0.00598802, 0.99401198],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94318182, 0.05681818],\n",
       "       [0.15697674, 0.84302326],\n",
       "       [0.95897436, 0.04102564],\n",
       "       [0.01630435, 0.98369565],\n",
       "       [0.57923497, 0.42076503],\n",
       "       [0.07526882, 0.92473118],\n",
       "       [1.        , 0.        ],\n",
       "       [0.78723404, 0.21276596],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.93684211, 0.06315789],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.23560209, 0.76439791],\n",
       "       [0.99418605, 0.00581395],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.84831461, 0.15168539],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.78723404, 0.21276596],\n",
       "       [0.92391304, 0.07608696],\n",
       "       [1.        , 0.        ],\n",
       "       [0.68852459, 0.31147541],\n",
       "       [0.4973262 , 0.5026738 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.88953488, 0.11046512],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.9010989 , 0.0989011 ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.72636816, 0.27363184],\n",
       "       [0.10227273, 0.89772727],\n",
       "       [0.47560976, 0.52439024],\n",
       "       [0.24210526, 0.75789474],\n",
       "       [0.        , 1.        ],\n",
       "       [0.84782609, 0.15217391],\n",
       "       [0.80927835, 0.19072165],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99465241, 0.00534759],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03431373, 0.96568627],\n",
       "       [0.95959596, 0.04040404],\n",
       "       [0.94797688, 0.05202312],\n",
       "       [1.        , 0.        ],\n",
       "       [0.52542373, 0.47457627],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0106383 , 0.9893617 ],\n",
       "       [0.99453552, 0.00546448],\n",
       "       [0.02659574, 0.97340426],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98275862, 0.01724138],\n",
       "       [0.        , 1.        ],\n",
       "       [0.07894737, 0.92105263],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00564972, 0.99435028],\n",
       "       [1.        , 0.        ],\n",
       "       [0.13559322, 0.86440678],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.37125749, 0.62874251],\n",
       "       [0.0923913 , 0.9076087 ],\n",
       "       [0.23255814, 0.76744186],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98181818, 0.01818182],\n",
       "       [0.17777778, 0.82222222],\n",
       "       [0.9902439 , 0.0097561 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96511628, 0.03488372],\n",
       "       [0.33714286, 0.66285714],\n",
       "       [0.98843931, 0.01156069],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02139037, 0.97860963],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03076923, 0.96923077],\n",
       "       [0.64516129, 0.35483871]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf2.oob_decision_function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=500,  max_leaf_nodes=16, n_jobs=-1, random_state = 42)\n",
    "rf_clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred_rf = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo saber cuáles fueron las variables que aportaton más a la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.11249225099876375\n",
      "sepal width (cm) 0.02311928828251033\n",
      "petal length (cm) 0.4410304643639577\n",
      "petal width (cm) 0.4233579963547682\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris= load_iris()\n",
    "rf_clf = RandomForestClassifier(n_estimators = 500, n_jobs = -1,random_state = 42)\n",
    "rf_clf.fit(iris['data'],iris['target'])\n",
    "\n",
    "for name, score in  zip (iris['feature_names'],rf_clf.feature_importances_):\n",
    "    print(name,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11249225, 0.02311929, 0.44103046, 0.423358  ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
